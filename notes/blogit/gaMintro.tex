%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
\input{../blogpost.tex}
\renewcommand{\basename}{gaMintro}
\renewcommand{\dirname}{notes/gabook/}
%\newcommand{\dateintitle}{}
%\newcommand{\keywords}{}
%\blogpage{http://sites.google.com/site/peeterjoot/math2009/gaMintro.pdf}
%\date{Nov 26, 2009}

\input{../peeter_prologue_print2.tex}

% these are environments.  use for example with \begin{definition} ... \end{definition}
% which of these am I using.  Move to thisbook.sty locations to allow for
% per-book customization.
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{definition}[theorem]{Definition}
\newtheorem{axiom}[theorem]{Axiom}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{remark}[theorem]{Remark}
%\newtheorem{claim}[theorem]{Claim}
%\newtheorem{problem}[theorem]{Problem}
%\newtheorem{exercise}[theorem]{Exercise}

%\beginArtNoToc
\beginArtWithToc

\generatetitle{GA intro culled from multivector matrix pendulum attempt}
\chapter{GA intro culled from multivector matrix pendulum attempt}
\label{chap:gaMintro}

\section{Prerequisites and preparation}

\subsection{Geometric Algebra fundamentals}

A minimal description of the prerequisites, nomenclature, and notation employed will be provided here.  The reader unfamiliar with geometric algebra is highly encouraged to refer to \citep{dorst2007gac} for an excellent general introduction to the mathematics, and \citep{doran2003gap} for physics centric applications and advanced topics.
%Similar Geometric Algebra boilerblate introductions unfortunately appear many papers.

At its core Geometric Algebra is a minimal set of axioms describing products of vectors.  For the purposes of this discussion assuming three dimensional Euclidean space, these are

\begin{axiom}
\begin{subequations}\label{axiom:gaMintro:all}
\begin{align}
\Ba (\Bb \Bc) = (\Ba \Bb) \Bc & \qquad \mbox{The product of any three vectors \(\Ba,\Bb,\Bc\) is associative} \\
(\Ba + \Bb) \Bc = \Ba \Bb + \Bb \Bc, \quad
\Ba (\Bb + \Bc) = \Ba \Bb + \Ba \Bc,
 & \qquad \mbox{Vector products are linear with respect to addition.} \\
\Ba^2 = \Abs{\Ba}^2 & \qquad \mbox{Square of a vector is the squared length of the vector.} \label{axiom:gaMintro:contraction}
\end{align}
\end{subequations}
\end{axiom}

Axiom \ref{axiom:gaMintro:contraction}, the contraction property, is generally metric dependent.  Introducing a Cartesian orthonormal basis \(\{\Be_k\}\) two specific and important consequences of \ref{axiom:gaMintro:all} are

\begin{definition}
\begin{subequations}\label{def:gaMintro:basics}
\begin{align}
\text{bivector} & \qquad \mbox{A product of two orthonormal vectors.} \\
\text{trivector} & \qquad \mbox{A product of three orthonormal vectors.} \\
\text{multivector} & \qquad \mbox{A sum of zero or more scalar, vector, bivector and trivector terms.}
\end{align}
\end{subequations}
\end{definition}

\begin{theorem}
\begin{subequations}\label{thm:gaMintro:basics}
\begin{align}
{\Bu}^2 = 1 & \qquad \mbox{Square of a unit vector \(\Bu\) is one.} \\
\Bu \Bv = -\Bv \Bu & \qquad \mbox{The product of two orthonormal unit vectors (a bivector) \(\Bu\), and \(\Bv\) anticommute.}
\end{align}
\end{subequations}
\end{theorem}

While there may be multiple representations for any given bivector or trivector, the intrinsic number of factors in such an object cannot be changed, and is called the grade.  Many specific operators may be defined in the algebra, the most fundamental of which is the grade selection operator.  If \(A = A_0 + A_1 + A_2 + A_3\) is a multivector composed of scalar, vector, bivector and trivectors terms respectively, one writes

\begin{definition}
\begin{subequations}\label{def:gaMintro:grade}
\begin{align}
\gpgrade{A}{k} &\equiv A_k \\
\gpgradezero{A} &\equiv A_0 \label{def:gaMintro:scalarSelection}
\end{align}
\end{subequations}
\end{definition}

It is convenient to omit the suffix, implying grade zero, for the important special case of scalar selection \ref{def:gaMintro:scalarSelection}.  The last operator required for this discussion will be the reversion operator.  One that replaces a multivector product of vector factors with one ordered exactly opposite.  For the reverse of a multivector \(A = \Ba_1 \Ba_2 \cdots \Ba_n\), we write

\begin{definition}
\begin{equation}\label{eqn:gaMintro:mp10}
\tilde{A} \equiv \Ba_n \cdots \Ba_2 \Ba_1
\end{equation}
\end{definition}

If \(A\) contains more than one grade, the reverse of that multivector is the sum of the reverse of all the individual grade terms is contains.  It has been pointed out that the reverse of a bivector negates that bivector.  Reversion of a trivector also negates it, while scalars and vector grades are unchanged by reversion.

\subsection{Unit bivectors and rotations}

A product of two perpendicular unit vectors can function as an imaginary for the plane spanned by these vectors.  Suppose we write for the \(y,z\) plane

\begin{equation}\label{eqn:gaMintro:mp20}
k = \Be_2 \Be_3,
\end{equation}

then we can demonstrate the negative square permuting one pair of vectors, then applying the contraction property twice

\begin{equation}\label{eqn:gaMintro:430}
\begin{aligned}
k^2
&= \Be_2 \Be_3 \Be_2 \Be_3 \\
&= -\Be_3 \mathLabelBox{\Be_2 \Be_2}{\(=1\)} \Be_3 \\
&= -\Be_3 \Be_3 \\
&= -1.
\end{aligned}
\end{equation}

This imaginary property allows for the construction of rotations using a complex number like polar form.  Given any unit bivector \(B\) we can define a bivector exponential

\begin{definition}
\begin{equation}\label{eqn:gaMintro:mp30}
e^{B\theta} \equiv \cos\theta + B\sin\theta.
\end{equation}
\end{definition}

This scalar plus bivector quantity is essentially a quaternion\footnote{Construction of quaternions equivalent to the traditional Hamiltonian form require an alternate metric.}.  Observe that such an exponential operator, acting on a vector rotates that vector.  For example in the \(y,z\) plane again, again with \(k = \Be_2 \Be_3\), we have

\begin{equation}\label{eqn:gaMintro:450}
\begin{aligned}
\Be_2 e^{k \theta}
&=
\Be_2 (\cos\theta + \Be_2 \Be_3 \sin\theta) \\
&=
\Be_2 \cos\theta + \mathLabelBox{\Be_2 \Be_2}{\(=1\)} \Be_3 \sin\theta.
\end{aligned}
\end{equation}

It should be noted that the equivalence with complex numbers is not exact.  In particular the action from the left and right of this form of quaternionic complex exponential is different

\begin{equation}\label{eqn:gaMintro:mp40}
\begin{aligned}
\Be_2 e^{\Be_2 \Be_3 \theta} = e^{-\Be_2 \Be_3 \theta} \Be_2.
\end{aligned}
\end{equation}

This property is generally true for any vector in the plane spanned by the plane of the bivector, but false for any vector perpendicular to that plane.  Instead such an exponential commutes with any vector (or component of a vector) that lies perpendicular to the plane.

\subsection{Parametrization of the spherical radial unit vector in Geometric Algebra}

%% DIAGRAMS.
Fundamental to the treatment of the spherical pendulum is an encoding of the radial unit spherical vector, say \(\rcap\).

We employing \(\theta\) for the polar angle, and \(\phi\) for the angle of the \(\rcap\) projected onto the \(x,y\) plane.

Two unit bivectors facilitate the parametrization of this spherical polar unit vector.  First, for the \(x,y\) plane, the use of

\begin{equation}\label{eqn:gaMintro:mp50}
i = \Be_1 \Be_2,
\end{equation}

allows for an polar form exponential rotation of vectors in the plane.  In particular, for the cylindrical outwards unit normal \(\hat{\Brho}\) at angle \(\phi\) from \(\Be_1\) we can write

\begin{equation}\label{eqn:gaMintro:mp60}
\hat{\Brho} = \Be_1 e^{i \phi}.
\end{equation}

The unit bivector for the plane of rotation between \(\Be_3\) and the spherical radial unit vector \(\rcap\) is

\begin{equation}\label{eqn:gaMintro:mp70}
j = \Be_3 \Be_1 e^{i \phi}.
\end{equation}

Finally, the spherical unit radial vector can be obtained by a single sided exponential rotation operator

\begin{equation}\label{eqn:gaMintro:mp80}
\rcap = \Be_3 e^{j \theta}
\end{equation}

%Because \(j\) contains \(\Be_3\) as a factor, double sided half angle rotation operators are not required.

%Diagrams help
%a lot.  Diagrams drawn in free-hand are not allowed.  Think of Arxiv as a real
%journal.  In my copernicus.tex, you may like to see how I drew graphics in my
%article using Latex. It is nice to draw things first in a finely ruled graphing
%paper.  After this, you can encode the points and lines and curves in Latex.  My
%favorite is \qbezier(x_1,y_1)(x_2,y_2)(x_3,y_3) command because I can draw
%anything with it.  You just need to understand that (x_1,y_1) and (x_3,y_3) are
%endpoints of the curve.  If you draw the tangent lines to the curve at these
%points and find the intersection of the lines, the position of the intersection
%is (x_2,y_2).

\subsection{Matrices with vector product elements}

Matrix algebra over the field of real numbers of complex numbers is familiar and well defined.  Geometric Algebra objects do not constitute a field, lacking multiplicative commutativity and a multiplicative inverses (particularly with mixed signature metrics).  Despite these limitations a matrix algebra employing multivector objects can be meaningfully defined.

For matrices \(A = {\begin{bmatrix} a_{ij} \end{bmatrix}}_{ij}\), \(B = {\begin{bmatrix} b_{ij} \end{bmatrix}}_{ij}\), and \(C = {\begin{bmatrix} c_{jk} \end{bmatrix}}_{jk}\) we define addition, multivector multiplication (replacing the usual scalar multiplication)

\begin{definition}
\begin{subequations}
\begin{align}
A + B &=
{\begin{bmatrix}
a_{ij} + b_{ij}
\end{bmatrix}}_{ij} & \qquad \mbox{Addition.}
\\
\alpha A &=
{\begin{bmatrix}
\alpha a_{ij}
\end{bmatrix}}_{ij}, \quad
A \alpha =
{\begin{bmatrix}
a_{ij} \alpha
\end{bmatrix}}_{ij}
& \qquad \mbox{Left and right multiplication by multivector \(\alpha\).}
\\
A C &=
{\begin{bmatrix}
\sum_m
a_{im} c_{mk}
\end{bmatrix}}_{ik} & \qquad \mbox{Matrix multiplication.} \label{def:gaMintro:mmult}
\end{align}
\end{subequations}
\end{definition}

Special note should be made that the factors within the matrix multiplication operation defined in \ref{def:gaMintro:mmult} were ordered specifically, and must not be commuted.

Define transposition in the usual fashion with \(a_{ji}\) the elements of \(A^\T\).  Additionally define a Hermitian conjugate operation as the transposed matrix with reversion applied to all elements

\begin{definition}
\begin{equation}\label{eqn:gaMintro:mp100}
A^\dagger = {\tilde{A}}^\T \qquad \mbox{Hermitian conjugation.}
\end{equation}
\end{definition}

As reversion induces a conjugate operation in a Euclidean multivector space, the dagger operation for this conjugate transposition is a natural choice.  It should however be noted that this is symbol is used in non-relativistic literature \citep{hestenes1999nfc} for reversion alone, and used still differently in a quantum mechanics context \citep{doran2003gap}.

\subsection{Factoring a vector into a product of matrices}

Because we have the capability of expressing vectors as multivector products, we can potentially factor a vector into a product of multivector matrices.

Two examples, both slightly different from our final application are considered.  First a three dimensional vector phasor sum, and then a scalar plus bivector factorization for the spherical unit vector.  This last will be similar to the more complex vector sums we will use in the N-pendulum problem later.

\subsubsection{A three dimensional phasor factored into matrices}

A three dimensional analogue of the typical complex number phasors used in electronics and wave theory is possible utilizing the exponential containing a trivector volume element.  For the unit trivector write \(I = \Be_1 \Be_2 \Be_3\).  The exponential

\begin{equation}\label{eqn:gaMintro:mp110}
R(\Bx, t) = \Br_0 e^{I(\Bk \cdot (\Bx - \Br_0) - \omega t)},
\end{equation}

then has vector and trivector grades.  Selecting just the vector grades, \(\gpgradeone{\Br(\Bx, t)} = \Br_0 \cos(\Bk \cdot (\Bx - \Br_0) - \omega t)\) we have a linear wave form propagating in space and time at a speed \(\omega/\Abs{\Bk}\).  Calculation of the square of the vector parts of two such phasors gives us the magnitude of the interference of the superposition wave.  We can utilize a matrix factorization of the result to group by either the vector amplitude or the phase induced interference terms as desired.  For example, let

\begin{equation}\label{eqn:gaMintro:mp120}
\begin{aligned}
R &= \Br e^{I\theta} \\
S &= \Bs e^{I\alpha}.
\end{aligned}
\end{equation}

The multivector sum of the two, \(T = R + S\), factored into a pair of matrices is

\begin{equation}\label{eqn:gaMintro:mp130}
\begin{aligned}
T &=
\begin{bmatrix}
\Br & \Bs
\end{bmatrix}
\begin{bmatrix}
e^{I\theta} \\
e^{I\alpha}
\end{bmatrix}
\end{aligned}
\end{equation}

If we write \(\Bt = \gpgradeone{T}\), and \(\Theta = \gpgradeone{\begin{bmatrix} e^{I\theta} \\ e^{I\alpha} \end{bmatrix}}\), we have

\begin{equation}\label{eqn:gaMintro:mp140}
\Bt =
\begin{bmatrix}
\Br & \Bs
\end{bmatrix}
\Theta.
\end{equation}

As a one by one matrix containing just a vector element, this equals its Hermitian conjugate, so for the magnitude of the vector sum we have

\begin{equation}\label{eqn:gaMintro:mp150}
\Bt
=
\begin{bmatrix}
\Br & \Bs
\end{bmatrix}
\Theta
\Theta^\dagger
\begin{bmatrix}
\Br \\ \Bs
\end{bmatrix}
=
\begin{bmatrix}
\Br & \Bs
\end{bmatrix}
\begin{bmatrix}
\cos^2 \theta & \cos\theta \cos\alpha \\
\cos\theta \cos\alpha & \cos^2 \alpha
\end{bmatrix}
\begin{bmatrix}
\Br \\ \Bs
\end{bmatrix}.
\end{equation}

Or, reversing the order of the products (conjugating as we do so), we get

\begin{equation}\label{eqn:gaMintro:mp160}
\Bt =
\Theta^\dagger
\begin{bmatrix}
\Br \\ \Bs
\end{bmatrix}
\begin{bmatrix}
\Br & \Bs
\end{bmatrix}
\Theta
=
\Theta^\dagger
\begin{bmatrix}
\Br^2 & \Br\Bs \\
\Bs\Br & \Bs^2
\end{bmatrix}
\Theta.
\end{equation}

Both of these when expanded out fully are just

\begin{equation}\label{eqn:gaMintro:mp170}
\Bt^2 =
\Br^2 \cos^2 \theta
+\Bs^2 \cos^2 \alpha
+ 2 \Br \cdot \Bs \cos\theta \cos\alpha.
\end{equation}

The matrix representation provides us a means to group together all the vector factors or all the phase factors.  Is this really useful?  Perhaps.  It does, however, illustrate how we can use the geometric product to create some representations that are unique to the algebra.  Lets continue to one more example, one where none of the matrix factors exclusively contain scalar elements.

\subsubsection{A spherical unit vector factorization}

Taking time derivatives of \eqnref{eqn:gaMintro:mp80} we have

\begin{equation}\label{eqn:gaMintro:470}
\begin{aligned}
\frac{d\rcap}{dt}
&= \Be_3 \frac{d}{dt} e^{j \theta} \\
&= \Be_3 \left( \frac{d\theta}{dt} j e^{j \theta} + \frac{dj}{dt} \sin\theta \right).
\end{aligned}
\end{equation}

We factor all the time derivatives into one column matrix, with
$\Omega =
\frac{d}{dt} \begin{bmatrix}
\theta \\
j
\end{bmatrix}$ for a sort of generalized angular velocity, and the remainder into a row matrix.  The resulting one by one matrix product of the two recovers our polar unit vector rate of change

\begin{equation}\label{eqn:gaMintro:mp180}
\frac{d\rcap}{dt}
= \Be_3
\begin{bmatrix}
j e^{j \theta} & \sin\theta
\end{bmatrix}
\Omega.
\end{equation}

Since this is a vector (or more properly a one by one matrix containing a vector), we can take the Hermitian conjugate of this matrix and leave it unchanged, allowing for an alternate factorization.
\begin{equation}\label{eqn:gaMintro:mp190}
\frac{d\rcap}{dt}
=
\Omega^\dagger
{\begin{bmatrix}
j e^{j \theta} & \sin\theta
\end{bmatrix}}^\dagger
%\begin{bmatrix}
%-e^{-j \theta} j \\
%\sin\theta
%\end{bmatrix}
\Be_3.
\end{equation}

The squared speed of the unit polar vector by multiplying \eqnref{eqn:gaMintro:mp180} with \eqnref{eqn:gaMintro:mp190}, like so

\begin{equation}\label{eqn:gaMintro:mp200}
\left( \frac{d\rcap}{dt} \right)^2 =
\Omega^\dagger
{\begin{bmatrix}
j e^{j \theta} & \sin\theta
\end{bmatrix}}^\dagger
\begin{bmatrix}
j e^{j \theta} & \sin\theta
\end{bmatrix}
\Omega
\end{equation}

Multiplying this out we have
\begin{equation}\label{eqn:gaMintro:mp210}
\left( \frac{d\rcap}{dt} \right)^2 =
\Omega^\dagger
\begin{bmatrix}
1 & -j e^{-j\theta}\sin\theta \\
j e^{j\theta}\sin\theta  & \sin^2\theta
\end{bmatrix}
\Omega
\end{equation}

Observe that the interior two by two matrix is Hermitian by definition \eqnref{eqn:gaMintro:mp100}.  Expanding the sums completely will eliminate the skew terms leaving just

\begin{equation}\label{eqn:gaMintro:mp220}
\left( \frac{d\rcap}{dt} \right)^2 =
\dot{\theta}^2 - \sin^2 \theta \left(\frac{dj}{dt}\right)^2.
\end{equation}

This example was primarily to illustrate one non-trivial way that a vector factorization is possible, and to justify the Hermitian conjugate label assigned to our transposed reversion operator \(\dagger\).

It is a fun diversion to use this result directly to form a multivector parametrized (scalar) Lagrangian for the spherical pendulum problem.  Lagrangian constraints must be added, and one must utilize the multivector generalization of the Euler-Lagrange equations to determine the equations of motion.  Because the three components of the bivector \(j\) add redundant degrees of freedom, such an approach needlessly complicates the problem.  A scalar angle parametrization works better and will be used below in the N-pendulum spherical generalization of this problem.
%  We will however, end up with a matrix of multivector (scalar and bivector) elements.

\section{Single spherical pendulum with geometric algebra}

As noted in \eqnref{eqn:mp80}, we can express the unit spherical vector using geometric algebra as

\begin{equation}\label{eqn:mp280}
\begin{aligned}
i &= \Be_1 \Be_2 \\
j &= \Be_3 \Be_1 e^{i \phi} \\
\rcap &= \Be_3 e^{j \theta}.
\end{aligned}
\end{equation}

Our unit vector derivative is then

\begin{equation}\label{eqn:gaMintro:490}
\begin{aligned}
\dot{\rcap}
&=
\frac{d}{dt} \left( \Be_3 e^{j \theta} \right) \\
&=
\Be_3 \left( j \dot{\theta} e^{j \theta} + \frac{d j }{dt} S_\theta \right)  \\
&=
\Be_3 \left( j \dot{\theta} e^{j \theta} + \Be_3 \Be_2 \dot{\phi} e^{i \phi} S_\theta \right)  \\
&=
\Be_1 e^{i\phi} e^{j \theta} \dot{\theta} + S_\theta \Be_2 e^{i \phi} \dot{\phi}
\end{aligned}
\end{equation}

Since any vector equals its own reverse we can also write

\begin{equation}\label{eqn:mp290}
\dot{\rcap} = e^{-j\theta} e^{-i \phi} \Be_1 \dot{\theta} + S_\theta e^{-i \phi} \Be_2 \dot{\phi}
\end{equation}

Squaring this for the unit vector speed we have

\begin{equation}\label{eqn:mp300}
\dot{\rcap}^2 =
\dot{\theta}^2 \mathLabelBox{\Be_1 e^{i\phi} e^{j \theta} e^{-j\theta} e^{-i \phi} \Be_1 }{\(=1\)}
+ S_\theta^2 \dot{\phi}^2 \mathLabelBox{\Be_2 e^{i \phi} e^{-i \phi} \Be_2 }{\(=1\)}
+
\dot{\theta}
\dot{\phi}
S_\theta
(
\Be_1 e^{i\phi} e^{j \theta}
e^{-i \phi} \Be_2
+ \Be_2 e^{i \phi}
e^{-j\theta} e^{-i \phi} \Be_1 )
\end{equation}

As a scalar we can write the last term explicitly using the scalar selection operator, and employ the cyclic reordering identity \(\gpgradezero{ab} = \gpgradezero{ba}\), which gives us

\begin{equation}\label{eqn:gaMintro:510}
\begin{aligned}
\Be_1 e^{i\phi} e^{j \theta}
e^{-i \phi} \Be_2
+ \Be_2 e^{i \phi}
e^{-j\theta} e^{-i \phi} \Be_1
&=
\gpgradezero{
- e^{-i \phi} i \Be_1 e^{i\phi} e^{j \theta}
+ e^{-i \phi} i e^{i \phi} e^{-j\theta}
} \\
&=
\gpgradezero{
- i (C_\theta + j S_\theta)
+ i (C_\theta - j S_\theta)
} \\
&=
- 2 S_\theta \gpgradezero{ i j } \\
&=
- 2 S_\theta \gpgradezero{ \Be_2 \Be_3 C_\phi + \Be_3 \Be_1 S_\phi } \\
\end{aligned}
\end{equation}

In the scalar selection all we have are bivectors, so this whole thing is zero.

So, while getting at the quadratic angular velocity terms was simpler using geometric algebra, showing that the cross terms were zero is certainly no easier using geometric algebra.  Messy trig reductions have been replaced by tricky grade selection operations.  In both cases we end up with the same result.

Is there a tidier way to do this?  Lets write instead

\begin{equation}\label{eqn:mp310}
\dot{\rcap}
=
\left( \frac{d}{dt}
\begin{bmatrix}
\theta & \phi
\end{bmatrix} \right)
\begin{bmatrix}
\Be_1 e^{i \phi} e^{j \theta} \\
\Be_2 e^{i \phi} S_\theta
\end{bmatrix}.
\end{equation}

With $\Theta = \begin{bmatrix}
\theta \\ \phi
\end{bmatrix}\(, and \)A =
\begin{bmatrix}
\Be_1 e^{i \phi} e^{j \theta} \\
\Be_2 e^{i \phi} S_\theta
\end{bmatrix}$, we have

\begin{equation}\label{eqn:gaMintro:530}
\begin{aligned}
\dot{\rcap}^2
&= \gpgradezero{\dot{\rcap}^2} \\
&= \gpgradezero{\dot{\Theta}^\dagger A A^\dagger \dot{\Theta}},
\end{aligned}
\end{equation}

which is just

\begin{equation}\label{eqn:mp320}
\dot{\rcap}^2 = \dot{\Theta}^\T \gpgradezero{ A A^\dagger } \dot{\Theta}.
\end{equation}

We have actually just calculated all the products in the interior matrix product, and we have

\begin{equation}\label{eqn:mp330}
\dot{\rcap}^2 = \dot{\Theta}^\T
\begin{bmatrix}
1 & 0 \\
0 & S_\theta^2
\end{bmatrix}
\dot{\Theta}.
\end{equation}

This diagonal quadratic form is now trivial to expand, and we therefore get the same result.

\EndArticle
