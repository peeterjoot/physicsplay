%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

% 
% 
\chapter{Fourier series Vacuum Maxwell's equations}\label{chap:PJFourierVacuum}
\index{Maxwell's equations!Fourier series}
%\date{Feb 03, 2009.  fourierSeriesMaxwell.tex}

\section{Motivation}

In \citep{bohm1989qt}, 
after finding a formulation of Maxwell's equations that he likes, his next
step is to assume the electric and magnetic fields can be expressed in 
a 3D Fourier series form, with periodicity in some repeated volume 
of space, and then proceeds to evaluate the energy of the 
field.

\subsection{Notation}

See the notational table \chapcite{notationTable} for much of the notation
assumed here.

\section{Setup}

Let us try this.  Instead of using the sine and cosine Fourier series
which looks more complex than it ought to be, use of a complex exponential
ought to be cleaner.

\subsection{3D Fourier series in complex exponential form}

For a multivector function \(f(\Bx, t)\), periodic in some rectangular spatial volume, let us assume that we have a
3D Fourier series representation.

Define the element of volume for our fundamental wavelengths to be the region bounded by three intervals in the \(x^1, x^2, x^3\) directions respectively

\begin{equation}\label{eqn:fourierSeriesMaxwell:20}
\begin{aligned}
I_1 &= [ a^1, a^1 + \lambda_1 ] \\
I_2 &= [ a^2, a^2 + \lambda_2 ] \\
I_3 &= [ a^3, a^3 + \lambda_3 ] \\
\end{aligned}
\end{equation}

Our assumed Fourier representation is then

\begin{equation}\label{eqn:fourierSeriesMaxwell:40}
\begin{aligned}
f(\Bx, t) &= \sum_{\Bk} \hat{f}_{\Bk}(t) \exp\left( - \sum_j \frac{2 \pi i k_j x^j}{\lambda_j} \right)
\end{aligned}
\end{equation}

Here \(\hat{f}_{\Bk} = \hat{f}_{\{k_1, k_2, k_3\}}\) is indexed over a triplet of integer values, and the \(k_1, k_2, k_3\) indices take on all integer values in the \([-\infty, \infty]\) range.

Note that we also wish to allow \(i\) to not just be a generic complex number, but allow for the use of either the Euclidean or Minkowski pseudoscalar

\begin{equation}\label{eqn:fourierSeriesMaxwell:60}
\begin{aligned}
i = \gamma_0 \gamma_1 \gamma_2 \gamma_3 = \sigma_1 \sigma_2 \sigma_3
\end{aligned}
\end{equation}

Because of this we should not assume that we can commute \(i\), or our exponentials with the functions \(f(\Bx,t)\), or \(\hat{f}_{\Bk}(t)\).

\begin{equation}\label{eqn:fourierSeriesMaxwell:80}
\begin{aligned}
\int_{x^1 = \partial I_1} &\int_{x^2 = \partial I_2} \int_{x^3 = \partial I_3} f(\Bx, t) 
e^{ 2 \pi i m_j x^j/\lambda_j}
dx^1 dx^2 dx^3 \\
&= \sum_{\Bk} \hat{f}_{\Bk}(t) \int_{x^1 = \partial I_1} \int_{x^2 = \partial I_2} \int_{x^3 = \partial I_3} dx^1 dx^2 dx^3 e^{ 2 \pi i (m_j - k_j) x^j/\lambda_j} dx^1 dx^2 dx^3
\end{aligned}
\end{equation}

But each of these integrals is just \(\delta_{\Bk,\Bm} \lambda_1 \lambda_2 \lambda_3\), giving us

\begin{equation}\label{eqn:fourierSeriesMaxwell:100}
\begin{aligned}
\hat{f}_{\Bk}(t)
&= \inv{\lambda_1 \lambda_2 \lambda_3 } \int_{x^1 = \partial I_1} \int_{x^2 = \partial I_2} \int_{x^3 = \partial I_3} f(\Bx, t) \exp\left( \sum_j \frac{2 \pi i k_j x^j}{\lambda_j} \right) dx^1 dx^2 dx^3 \\
\end{aligned}
\end{equation}

To tidy things up 
lets invent (or perhaps abuse) some notation to tidy things up.  As a subscript on our Fourier coefficients we have used \(\Bk\) as an index.
Let us also use it as a vector, and define

\begin{equation}\label{eqn:fourierSeriesMaxwell:120}
\begin{aligned}
\Bk \equiv 2 \pi \sum_m \frac{\sigma^m k_m}{\lambda_m}
\end{aligned}
\end{equation}

With our spatial vector \(\Bx\) written

\begin{equation}\label{eqn:fourierSeriesMaxwell:140}
\begin{aligned}
\Bx = \sum_m \sigma_m x^m
\end{aligned}
\end{equation}

We now have a \(\Bk \cdot \Bx\) term in the exponential, and can remove when desirable the coordinate summation.  If we write \(V = \lambda_1 \lambda_2 \lambda_3\)
it leaves a nice tidy notation for the 3D Fourier series over the volume

\begin{equation}\label{eqn:fourierSeriesMaxwell:160}
\begin{aligned}
f(\Bx, t) &= \sum_{\Bk} \hat{f}_{\Bk}(t) e^{ - i \Bk \cdot \Bx } \\
\hat{f}_{\Bk}( t) &= \inv{V} \int f(\Bx, t) e^{ i \Bk \cdot \Bx } d^3 x
\end{aligned}
\end{equation}

This allows us to proceed without caring about the specifics of the lengths of the sides of the rectangular prism that defines the periodicity of the signal
in question.

\subsection{Vacuum equation}

Now that we have a desirable seeming Fourier series representation, we 
want to apply this to Maxwell's equation for the vacuum.  We will use the 
STA formulation of Maxwell's equation, but use the unit convention of Bohm's
book.

In \chapcite{PJrayleighJeans} the STA equivalent to Bohm's notation 
for Maxwell's equations was found to be

\begin{equation}\label{eqn:fourier_series_maxwell:maxwell}
\begin{aligned}
F &= \bcE + i\bcH \\
J &= (\rho + \Bj) \gamma_0 \\
\grad F &= 4 \pi J
\end{aligned}
\end{equation}

This is the CGS form of Maxwell's equation, but with the old style \(\bcH\) for \(c\BB\), and \(\bcE\) for \(\BE\).  In more recent texts \(\bcE\) (as a non-vector) is reserved for electromotive flux.  In this set of notes I use Bohm's notation, since the aim is to clarify for myself aspects of his treatment.

For the vacuum equation, we make an explicit spacetime split by premultiplying with \(\gamma_0\)

\begin{equation}\label{eqn:fourierSeriesMaxwell:180}
\begin{aligned}
\gamma_0 \grad 
&= \gamma_0 
\lr{ \gamma^0 \partial_0 + \gamma^k \partial_k } \\
&= \partial_0 - \gamma^k \gamma_0 \partial_k \\
&= \partial_0 + \gamma_k \gamma_0 \partial_k \\
&= \partial_0 + \sigma_k \partial_k \\
&= \partial_0 + \spacegrad \\
\end{aligned}
\end{equation}

So our vacuum equation is just

\begin{equation}\label{eqn:fourier_series_maxwell:vacuumMaxwell}
\begin{aligned}
(\partial_0 + \spacegrad) F = 0
\end{aligned}
\end{equation}

\section{First order vacuum solution with Fourier series}

\subsection{Basic solution in terms of undetermined coefficients}

Now that a notation for the 3D Fourier series has been established, we
can assume a series solution for our field of the form

\begin{equation}\label{eqn:fourier_series_maxwell:assumed}
\begin{aligned}
F(\Bx,t) = \sum_{\Bk} \hat{F}_{\Bk}(t) e^{-2\pi i k_j x^j/\lambda_j}
\end{aligned}
\end{equation}

can now apply this to the vacuum Maxwell equation \eqnref{eqn:fourier_series_maxwell:vacuumMaxwell}.
This gives us

\begin{equation}\label{eqn:fourierSeriesMaxwell:200}
\begin{aligned}
\sum_{\Bk} \left(\partial_t \hat{F}_{\Bk}(t) \right) e^{-2\pi i k_j x^j/\lambda_j}
&= -c \sum_{\Bk, m} \sigma^m \hat{F}_{\Bk}(t) \PD{x^m}{} e^{-2\pi i k_j x^j/\lambda_j} \\
&= -c \sum_{\Bk, m} \sigma^m \hat{F}_{\Bk}(t) \left(-2 \pi \frac{k_m}{\lambda_m}\right) e^{-2\pi i k_j x^j/\lambda_j} \\
&= 2 \pi c \sum_{\Bk} \sum_m \frac{\sigma^m k_m}{\lambda_m} \hat{F}_{\Bk}(t) i e^{-2\pi i k_j x^j/\lambda_j} \\
\end{aligned}
\end{equation}


Note that \(i\) commutes with \(\Bk\) and since \(F\) is also an STA bivector \(i\) commutes with \(F\).  Putting all this together we have

\begin{equation}\label{eqn:fourierSeriesMaxwell:220}
\begin{aligned}
\sum_{\Bk} \left(\partial_t \hat{F}_{\Bk}(t) \right) e^{-i \Bk \cdot \Bx }
&= i c \sum_{\Bk} \Bk \hat{F}_{\Bk}(t) e^{- i \Bk \cdot \Bx } \\
\end{aligned}
\end{equation}

Term by term we now have a (big ass, triple infinite) set of very simple first order differential equations, one for each \(\Bk\) triplet of indices.  Specifically this is

\begin{equation}\label{eqn:fourierSeriesMaxwell:240}
\begin{aligned}
\hat{F}_{\Bk}' &= i c \Bk \hat{F}_{\Bk}
\end{aligned}
\end{equation}

With solutions

\begin{equation}\label{eqn:fourierSeriesMaxwell:260}
\begin{aligned}
\hat{F}_{0} &= C_{0} \\
\hat{F}_{\Bk} &= \exp\left(i c \Bk t \right) C_{\Bk} \\
\end{aligned}
\end{equation}

Here \(C_{\Bk}\) is an undetermined STA bivector.  For now we keep this undetermined coefficient on the right hand side of the exponential since no demonstration that it commutes with a factor of the form \(\exp(i\Bk\phi)\).  Substitution back into our assumed solution sum we have a solution to Maxwell's equation, in terms of a set of as yet undetermined (bivector) coefficients

\begin{equation}\label{eqn:fourierSeriesMaxwell:280}
\begin{aligned}
F(\Bx,t) = C_0 + \sum_{\Bk \ne 0} \exp\left(i c \Bk t \right) C_{\Bk} \exp(-i \Bk \cdot \Bx )
\end{aligned}
\end{equation}

The special case of \(\Bk = 0\) is now seen to be not so special and can be brought into the sum.  

\begin{equation}\label{eqn:fourierSeriesMaxwell:300}
\begin{aligned}
F(\Bx,t) = \sum_{\Bk} \exp\left(i c \Bk t \right) C_{\Bk} \exp(-i \Bk \cdot \Bx )
\end{aligned}
\end{equation}

We can also 
take advantage of the bivector nature of \(C_{\Bk}\), which implies the complex exponential can commute to the left, since the two fold commutation with the pseudoscalar with change sign twice.
%  A similar right commutation of the \(i\Bk\) exponential cannot be justified, and without more thought I am unsure if it can be allowed?

\begin{equation}\label{eqn:fourier_series_maxwell:undetermined}
\begin{aligned}
F(\Bx,t) = \sum_{\Bk} 
\exp\left(i \Bk c t \right) 
\exp\left(-i \Bk \cdot \Bx \right) 
C_{\Bk} 
\end{aligned}
\end{equation}

\subsection{Solution as time evolution of initial field}

Now, observe the form of this sum for \(t=0\).  This is

\begin{equation}\label{eqn:fourierSeriesMaxwell:320}
\begin{aligned}
F(\Bx,0) 
&= \sum_{\Bk} C_{\Bk} \exp(-i \Bk \cdot \Bx ) \\
\end{aligned}
\end{equation}

So, the \(C_k\) coefficients are precisely the Fourier coefficients of \(F(\Bx,0)\).  This is to be expected having repeatedly seen similar results in the Fourier transform treatments of 
\chapcite{PJfourierMaxwellSecondOrder}, \chapcite{PJfirstOrderMaxwell}, and \chapcite{PJ4dFourier}.
We then have an equation for the complete time evolution of any spatially periodic electrodynamic field in terms of the field value at all points in the region at some initial time.  Summarizing so far this is

\begin{equation}\label{eqn:fourierSeriesMaxwell:340}
\begin{aligned}
F(\Bx,t) &= \sum_{\Bk} \exp\left(i c \Bk t \right) 
C_{\Bk}
\exp(-i \Bk \cdot \Bx) \\
C_{\Bk}
&= \inv{V} \int F(\Bx', 0) \exp\left( i\Bk \cdot \Bx' \right) d^3 x'
\end{aligned}
\end{equation}

Regrouping slightly we can write this as a convolution with a Fourier kernel (a Green's function).  That is

\begin{equation}\label{eqn:fourier_series_maxwell:bivectorSolNonGreens}
\begin{aligned}
F(\Bx,t) &= \inv{V} \int \sum_{\Bk} \exp\left( i \Bk ct \right) \exp\left( i \Bk \cdot (\Bx' - \Bx) \right) F(\Bx', 0) d^3 x'
\end{aligned}
\end{equation}

Or
\begin{equation}\label{eqn:fourier_series_maxwell:bivectorSolution}
\begin{aligned}
F(\Bx,t) &= \int G(\Bx - \Bx', t) F(\Bx', 0) d^3 x' \\
G(\Bx,t) &= \inv{V} \sum_{\Bk} \exp\left( i \Bk ct \right) \exp\left( -i \Bk \cdot \Bx \right)
\end{aligned}
\end{equation}

Okay, that is cool.  We have now got the basic periodicity result directly from Maxwell's equation in one shot.  No need to drop down to
potentials, or even the separate electric or magnetic components of our field \(F = \bcE + i \bcH\).

\subsection{Prettying it up?  Questions of commutation}

Now, it is tempting here to write 
\eqnref{eqn:fourier_series_maxwell:undetermined}
as a single exponential

% k = kcappa g_0 |k|
% kcap g_0 = kcappa 
\begin{equation}\label{eqn:fourier_series_maxwell:isItValid}
\begin{aligned}
F(\Bx,t) 
%&= \sum_{\Bk} e^{i \Abs{\Bk}( \kcap c t - \kcap \cdot \Bx)} C_{\Bk} \\
&= \sum_{\Bk} \exp\left(i \Bk c t - i\Bk \cdot \Bx \right) C_{\Bk} \quad\quad \mbox{VALID?}
\end{aligned}
\end{equation}

This would probably allow for a prettier four vector form in terms of \(x = x^\mu \gamma_\mu\) replacing the separate \(\Bx\) and \(x^0 = ct\) terms.
However, 
such a grouping is not allowable unless one first demonstrates that \(e^{i \Bu }\), and \(e^{i \alpha }\), for spatial vector \(\Bu\) and scalar \(\alpha\) commute!

To demonstrate that this is in fact the case 
note that exponential
of this dual spatial vector can be written

\begin{equation}\label{eqn:fourierSeriesMaxwell:360}
\begin{aligned}
\exp( i \Bu ) &= \cos( \Bu ) + i \sin( \Bu ) \\
\end{aligned}
\end{equation}

This spatial vector cosine, \(\cos(\Bu)\), is a scalar (even powers only), and our sine, \(\sin(\Bu) \propto \Bu\), is a spatial vector in the direction of \(\Bu\) (odd powers leaves a vector times a scalar).  Spatial vectors commute with \(i\) (toggles sign twice percolating its way through), therefore pseudoscalar exponentials also commute with \(i\).

This will simplify a lot, and it shows that \eqnref{eqn:fourier_series_maxwell:isItValid} is in fact a valid representation.

Now, there is one more question of commutation here.  Namely, does a dual spatial vector exponential commute with the field itself
(or equivalently, one of the Fourier coefficients).

Expanding such a product and attempting term by term commutation should show

\begin{equation}\label{eqn:fourierSeriesMaxwell:380}
\begin{aligned}
e^{i\Bu} F
&= (\cos \Bu + i\sin\Bu) (\bcE + i\bcH) \\
&= i\sin\Bu (\bcE + i\bcH) + (\bcE + i\bcH) \cos\Bu \\
&= i (\sin\Bu) \bcE - (\sin\Bu) \bcH + F \cos\Bu \\
&= i (-\bcE \sin\Bu + 2 \bcE \cdot \sin\Bu ) + (\bcH \sin\Bu - 2 \bcH \cdot \sin\Bu ) + F \cos\Bu \\
&= 2 \sin\Bu \cdot (\bcE - \bcH) + F (\cos\Bu -i\sin\Bu) \\
\end{aligned}
\end{equation}

That is
\begin{equation}\label{eqn:fourier_series_maxwell:anticommutes}
\begin{aligned}
e^{i\Bu} F &= 2 \sin\Bu \cdot (\bcE - \bcH) + F e^{-i\Bu}
\end{aligned}
\end{equation}

This exponential has one anticommuting term, but also has a scalar component introduced by the portions of the electric
and magnetic fields that are colinear with the spatial vector \(\Bu\).

%
%Would this look any tidier in terms of unit wave number vector \(\Bk = \Abs{\Bk} \kcap\)?  Let us see
%
%\begin{align*}
%F(\Bx,t) = \sum_{\Bk} \exp\left(-i \Abs{\Bk}(\kcap \cdot \Bx - \kcap c t) \right) C_{\Bk} 
%\end{align*}
%FIXME:EXP: above.
%
%Perhaps not.
%
%One thing we may do however, is perform a summation swap and sum over all
%triplets \(-\Bk\) instead, with a redefition of the undetermined
%coefficients \(C_{\Bk}\) as \(C_{-\Bk}\) (incorporating the effects of that sign swap into the value of these coefficients).  This takes the sign out of the exponential and pretties it up slightly.
%
%\begin{align*}
%F(\Bx,t) = \sum_{\Bk} e^{i \Bk \cdot \Bx - i\Bk c t} C_{\Bk} 
%\end{align*}
%FIXME:EXP: above.
%
%There was also the notational trick noticed in the Fourier transform treatment 
%where a conversion of these separate space and time exponential factors into a single
%four vector dot product was possible.  That should work here a bit better than in the Fourier transform case.
%
%FIXME: detail that here.  Want to see what that implies for a Lorentz transformation of the field.

\section{Field Energy and momentum}

Given that we have the same structure for our four vector potential solutions as the complete bivector field, it does not appear that there is much
reason to work in the second order quantities.  Following Bohm we should now be prepared to express the field energy density and
momentum density in terms of the Fourier coefficients, however unlike Bohm, let us try this using the first order 
solutions found above.

In CGS units (see \chapcite{PJrayleighJeans} for verification) these field energy and momentum densities (Poynting vector \(\BP\)) are, respectively

\begin{equation}\label{eqn:fourierSeriesMaxwell:400}
\begin{aligned}
E &= \inv{8\pi} 
\lr{ {\bcE}^2 + \bcH^2 } \\
\BP &= \inv{4\pi} (\bcE \cross \bcH )
\end{aligned}
\end{equation}

Given that we have a complete field equation without an explicit separation of electric and magnetic components, perhaps this
is easier to calculate from the stress energy four vector for energy/momentum.  In CGS units this must be

\begin{equation}\label{eqn:fourierSeriesMaxwell:420}
\begin{aligned}
T(\gamma_0) &= \inv{8\pi} F \gamma_0 \tilde{F}
\end{aligned}
\end{equation}

An expansion of this to verify the CGS conversion seems worthwhile.

\begin{equation}\label{eqn:fourierSeriesMaxwell:440}
\begin{aligned}
T(\gamma_0) 
&= \inv{8\pi} F \gamma_0 \tilde{F} \\
&= \frac{-1}{8\pi} (\bcE + i\bcH) \gamma_0 (\bcE + i\bcH) \\
&= \frac{1}{8\pi} (\bcE + i\bcH) (\bcE - i\bcH) \gamma_0 \\
&= \frac{1}{8\pi} \left( \bcE^2 - (i\bcH)^2 + i(\bcH \bcE - \bcE \bcH) \right) \gamma_0 \\
&= \frac{1}{8\pi} \left( \bcE^2 + \bcH^2 + 2 i^2 \bcH \cross \bcE \right) \gamma_0 \\
&= \frac{1}{8\pi} \left( \bcE^2 + \bcH^2 \right) \gamma_0 + \inv{4 \pi} \left(\bcE \cross \bcH \right) \gamma_0 \\
\end{aligned}
\end{equation}

Good, as expected we have 

\begin{equation}\label{eqn:fourierSeriesMaxwell:460}
\begin{aligned}
E &= T(\gamma_0) \cdot \gamma_0 \\
\BP &= T(\gamma_0) \wedge \gamma_0
\end{aligned}
\end{equation}

FIXME: units here for \(\BP\) are off by a factor of \(c\).  This does not matter
so much in four vector form \(T(\gamma_0)\) where the units naturally take care
of themselves.

Okay, let us apply this to our field \eqnref{eqn:fourier_series_maxwell:bivectorSolNonGreens}, and try to percolate the \(\gamma_0\) through all the terms of \(\tilde{F}(\Bx,t)\)

\begin{equation}\label{eqn:fourierSeriesMaxwell:480}
\begin{aligned}
\gamma_0 \tilde{F}(\Bx,t) 
&= -\gamma_0 F(\Bx,t) \\
&= -\gamma_0 \inv{V} \int \sum_{\Bk} \exp\left( i \Bk ct \right) \exp\left( i \Bk \cdot (\Bx' -\Bx) \right) F(\Bx', 0) d^3 x' \\
\end{aligned}
\end{equation}

Taking one factor at a time 

\begin{equation}\label{eqn:fourierSeriesMaxwell:500}
\begin{aligned}
\gamma_0 \exp\left( i \Bk ct \right) 
&= \gamma_0 (\cos\left( \Bk ct \right) + i \sin\left( \Bk ct \right) ) \\
&= \cos\left( \Bk ct \right) \gamma_0 - i \gamma_0 \sin\left( \Bk ct \right) ) \\
&= \cos\left( \Bk ct \right) \gamma_0 - i \sin\left( \Bk ct \right) ) \gamma_0 \\
&= \exp\left( -i \Bk ct \right) \gamma_0
\end{aligned}
\end{equation}


Next, percolate \(\gamma_0\) through the pseudoscalar exponential.

\begin{equation}\label{eqn:fourierSeriesMaxwell:520}
\begin{aligned}
\gamma_0 e^{i\phi} 
&= \gamma_0 (\cos\phi + i \sin\phi) \\
&= \cos\phi \gamma_0 - i \gamma_0 \sin\phi \\
&= e^{-i\phi} \gamma_0
\end{aligned}
\end{equation}

Again, the percolation produces a conjugate effect.  Lastly, as noted previously \(F\) commutes with \(i\).  We have therefore

\begin{equation}\label{eqn:fourierSeriesMaxwell:540}
\begin{aligned}
\tilde{F}(\Bx,t) \gamma_0 {F}(\Bx,t) \gamma_0
&=
\frac{1}{V^2} \int \sum_{\Bk,\Bm} 
F(\Ba, 0) 
e^{i \Bk \cdot (\Ba -\Bx) }
e^{ i \Bk ct }
e^{ -i \Bm ct } e^{ -i \Bm \cdot (\Bb -\Bx) } F(\Bb, 0) d^3 a d^3 b \\
&= \frac{1}{V^2} \int \sum_{\Bk,\Bm} F(\Ba, 0) e^{ i \Bk \cdot \Ba -i \Bm \cdot \Bb + i (\Bk -\Bm) ct -i (\Bk - \Bm) \cdot \Bx } F(\Bb, 0) d^3 a d^3 b \\
&= \frac{1}{V^2} \int \sum_{\Bk} F(\Ba, 0) F(\Bb, 0) e^{ i \Bk \cdot (\Ba - \Bb) } d^3 a d^3 b \\
&\quad + \frac{1}{V^2} \int \sum_{\Bk \ne \Bm} F(\Ba, 0) e^{ i \Bk \cdot \Ba -i \Bm \cdot \Bb + i (\Bk -\Bm) ct -i (\Bk - \Bm) \cdot \Bx } F(\Bb, 0) d^3 a d^3 b \\
&= \frac{1}{V^2} \int \sum_{\Bk} F(\Ba, 0) F(\Bb, 0) e^{ i \Bk \cdot (\Ba - \Bb) } d^3 a d^3 b \\
&\quad + \frac{1}{V^2} \int \sum_{\Bm, \Bk \ne 0} F(\Ba, 0) e^{ 
i \Bm \cdot (\Ba -\Bb) 
+i \Bk \cdot (\Ba -\Bx)
+ i \Bk ct 
} F(\Bb, 0) d^3 a d^3 b \\
\end{aligned}
\end{equation}

Hmm.  Messy.  The scalar bits of the above are our energy.  We have a \(F^2\) like term in the first integral (like the Lagrangian density), but it is at different points, and
we have to integrate those with a sort of vector convolution.  Given the reciprocal relationships between convolution and multiplication moving between the frequency and time domains in Fourier transforms I had expect that this first integral can somehow be turned into the sum of the squares of all the Fourier coefficients

\begin{equation}\label{eqn:fourierSeriesMaxwell:560}
\begin{aligned}
\sum_{\Bk} C_{\Bk}^2 
\end{aligned}
\end{equation}

which is very much like a discrete version of the Rayleigh energy theorem as derived in \chapcite{PJqmFourier}, and is in this case
a constant (not a function of time or space) and is dependent on only the initial field.
That would mean that the remainder is the Poynting vector,
which looks reasonable since it has the appearance of being somewhat antisymmetric.

Hmm, having mostly figured it out without doing the math in this case, the answer pops out.  This first integral can be separated cleanly since the pseudoscalar
exponentials commute with the bivector field.  We then have

\begin{equation}\label{eqn:fourierSeriesMaxwell:580}
\begin{aligned}
\frac{1}{V^2} &\int \sum_{\Bk} F(\Ba, 0) F(\Bb, 0) e^{ i \Bk \cdot (\Ba - \Bb) } d^3 a d^3 b \\
&= \frac{1}{V} \int \sum_{\Bk} F(\Ba, 0) e^{ i \Bk \cdot \Ba } d^3 a \int F(\Bb, 0) e^{ -i \Bk \cdot \Bb } d^3 b \\
&= \sum_{\Bk} \hat{F}_{-\Bk} \hat{F}_{\Bk} \\
\end{aligned}
\end{equation}

A side note on subtle notational sneakiness here.  In the assumed series 
solution of \eqnref{eqn:fourier_series_maxwell:assumed} \(\hat{F}_{\Bk}(t)\) was the \(\Bk\) Fourier coefficient of \(F(\Bx,t)\), whereas here the use of \(\hat{F}_{\Bk}\) has been used to denote the \(\Bk\) Fourier coefficient of \(F(\Bx,0)\).
An alternative considered and rejected was something messier like \(\widehat{F(t=0)}_{\Bk}\), or the use of the original, less physically significant, \(C_{\Bk}\) coefficients.

The second term could also use a simplification, and it looks like we can separate these \(\Ba\) and \(\Bb\) integrals too

\begin{equation}\label{eqn:fourierSeriesMaxwell:600}
\begin{aligned}
\frac{1}{V^2} &\int \sum_{\Bm, \Bk \ne 0} F(\Ba, 0) e^{ 
i \Bm \cdot (\Ba -\Bb) 
+i \Bk \cdot (\Ba -\Bx)
+ i \Bk ct 
} F(\Bb, 0) d^3 a d^3 b \\
&=\frac{1}{V} \int \sum_{\Bm, \Bk \ne 0} F(\Ba, 0) e^{ i (\Bm + \Bk) \cdot \Ba } d^3 a
e^{ i \Bk ct -i \Bk \cdot \Bx }
\inv{V} \int F(\Bb, 0) 
e^{-i \Bm \cdot \Bb}
d^3 b
 \\
&= \sum_{\Bm} \sum_{\Bk \ne 0} \hat{F}_{-\Bm -\Bk} e^{ i \Bk ct -i \Bk \cdot \Bx } \hat{F}_{\Bm} \\
\end{aligned}
\end{equation}

Making an informed guess that the first integral is a scalar, and the second is a spatial vector, our energy and momentum densities (Poynting vector) respectively are

\begin{equation}\label{eqn:fourier_series_maxwell:energyMomentum}
\begin{aligned}
U & 
\questionEquals
 \inv{8 \pi} \sum_{\Bk} \hat{F}_{-\Bk} \hat{F}_{\Bk} \\
\BP &
\questionEquals
 \inv{8 \pi} \sum_{\Bm} \sum_{\Bk \ne 0} \hat{F}_{-\Bm -\Bk} e^{ i \Bk ct -i \Bk \cdot \Bx } \hat{F}_{\Bm}
\end{aligned}
\end{equation}

Now that much of the math is taken care of, more consideration about the physics implications is required.  In particular, relating these
abstract quantities to the frequencies and the harmonic oscillator model as Bohm did is desirable (that was the whole point of the exercise).

On the validity of \eqnref{eqn:fourier_series_maxwell:energyMomentum}, it is not unreasonable to expect that 
\(\PDi{t}{U} = 0\), and \(\spacegrad \cdot \BP = 0\) separately in these current free conditions from the energy momentum conservation relation

\begin{equation}\label{eqn:fourierSeriesMaxwell:620}
\begin{aligned}
\PD{t}{}\frac{1}{8\pi} \left(\bcE^2 + \bcH^2\right) + \inv{4\pi} \spacegrad \cdot (\bcE \cross \bcH) &= -\bcE \cdot \Bj 
\end{aligned}
\end{equation}

Note that an SI derivation of this relation can be found in \chapcite{PJpoynting}.  So it therefore makes some sense that all the time dependence ends
up in what has been labeled as the Poynting vector.  A proof that the spatial divergence of this quantity is zero would help validate
the guess made (or perhaps invalidate it).

Hmm.  Again on the validity of identifying the first sum with the energy.  It does not appear to work for the \(\Bk = 0\) case, since that gives you

\begin{equation}\label{eqn:fourierSeriesMaxwell:640}
\begin{aligned}
\inv{8 \pi V^2} \int F(\Ba, 0) F(\Bb, 0) d^3 a d^3b
\end{aligned}
\end{equation}

That is only a scalar if the somehow all the non-scalar parts of that product somehow magically cancel out.
Perhaps it is true that the second sum has no scalar part, and if that is the case one would have

\begin{equation}\label{eqn:fourierSeriesMaxwell:660}
\begin{aligned}
U
\questionEquals
 \inv{8 \pi} \sum_{\Bk} \gpgradezero{\hat{F}_{-\Bk} \hat{F}_{\Bk}} \\
\end{aligned}
\end{equation}

An explicit calculation of \(T(\gamma_0) \cdot \gamma_0\) is probably justified
to discarding all other grades, and get just the energy.

So, instead of optimistically hoping that the scalar and spatial vector terms will automatically fall out, it appears
that we have to explicitly calculate the dot and wedge products, as in

\begin{equation}\label{eqn:fourierSeriesMaxwell:680}
\begin{aligned}
U &= -\frac{1}{16\pi}( F \gamma_0 F \gamma_0 + \gamma_0 F \gamma_0 F ) \\
\BP &= -\frac{1}{16\pi}( F \gamma_0 F \gamma_0 - \gamma_0 F \gamma_0 F )
\end{aligned}
\end{equation}

and then substitute our Fourier series solution for \(F\) to get the desired result.  This appears to be getting more complex instead of
less so unfortunately, but hopefully following this to a logical conclusion will show in retrospect a faster way to the desired result.
A first attempt to do so shows that we have to return to our assumed Fourier solution and revisit some of the assumptions made.

\section{Return to the assumed solutions to Maxwell's equation}

An initial attempt to expand \eqnref{eqn:fourier_series_maxwell:energyMomentum} properly
given the Fourier specification of the Maxwell solution
gets into trouble.  Consideration of some special cases for specific values
of \(\Bk\) shows that there is a problem with the grades of the solution.

Let us reexamine the assumed solution of \eqnref{eqn:fourier_series_maxwell:bivectorSolNonGreens} with respect to grade
\begin{equation}\label{eqn:fourierSeriesMaxwell:700}
\begin{aligned}
F(\Bx,t) &= \inv{V} \int \sum_{\Bk} \exp\left( i \Bk ct \right) \exp\left( i \Bk \cdot (\Bx' - \Bx) \right) F(\Bx', 0) d^3 x'
\end{aligned}
\end{equation}

For scalar Fourier approximations we are used to the ability to select a subset of the Fourier terms to approximate the field, but
except for the \(\Bk = 0\) term it appears that a term by term approximation actually introduces noise in the form of non-bivector grades.

Consider first the \(\Bk = 0\) term.  This gives us a first order approximation of the field which is

\begin{equation}\label{eqn:fourierSeriesMaxwell:720}
\begin{aligned}
F(\Bx,t) &\approx \inv{V} \int F(\Bx', 0) d^3 x'
\end{aligned}
\end{equation}

As summation is grade preserving this spatial average of the initial field conditions does have the required grade as desired.
Next consider a non-zero Fourier term such as \(\Bk = \{1,0,0\}\).  For this single term approximation of the field let us write
out the field term as

\begin{equation}\label{eqn:fourierSeriesMaxwell:740}
\begin{aligned}
F_{\Bk}(\Bx,t)
&= \inv{V} \int e^{ i \kcap \Abs{\Bk} ct + i \Bk \cdot (\Bx' - \Bx) } (\bcE(\Bx', 0) + i\bcH(\Bx', 0)) d^3 x'
\end{aligned}
\end{equation}

Now, let us expand the exponential.  This was shorthand for the product of the exponentials, which seemed to be a reasonable
shorthand since we showed they commute.  Expanded out this is

\begin{equation}\label{eqn:fourierSeriesMaxwell:760}
\begin{aligned}
\exp&( i \kcap \Abs{\Bk} ct + i \Bk \cdot (\Bx' - \Bx) ) \\
&= (\cos( {\Bk} ct ) + i \kcap \sin( \Abs{\Bk} ct ))( \cos( \Bk \cdot (\Bx' - \Bx) ) + i \sin(\Bk \cdot (\Bx' - \Bx) )) \\
\end{aligned}
\end{equation}

For ease of manipulation write \(\Bk \cdot (\Bx' - \Bx) = k \Delta x\), and \(\Bk c t = \Bomega t\), we have

\begin{equation}\label{eqn:fourierSeriesMaxwell:780}
\begin{aligned}
%(\cos( \Bomega t ) + i \sin( \Bomega t ))( \cos( k \Delta x ) ) + i \sin( k \Delta x ) )) 
\exp( i \Bomega t + i k \Delta x )
&= \cos( \Bomega t ) \cos( k \Delta x ) +i \cos( \Bomega t ) \sin( k \Delta x ) \\
&+i \sin( \Bomega t ) \cos( k \Delta x ) - \sin( \Bomega t ) \sin( k \Delta x )  \\
\end{aligned}
\end{equation}

Note that \(\cos(\Bomega t)\) is a scalar, whereas \(\sin(\Bomega t)\) is a (spatial) vector in the direction of \(\Bk\).
Multiplying this out with the initial time field \(F(\Bx',0) = \bcE(\Bx', 0) + i\bcH(\Bx',0) = \bcE' + i\bcH'\) we can separate into grades.  

\begin{equation}\label{eqn:fourierSeriesMaxwell:800}
\begin{aligned}
\exp&( i \Bomega t + i k \Delta x ) (\bcE' + i\bcH') \\
&= \cos( \Bomega t ) (\bcE' \cos( k \Delta x ) -\bcH' \sin( k \Delta x ) ) +  \sin( \Bomega t ) \cross ( \bcH' \sin( k \Delta x ) - \bcE' \cos( k \Delta x ) ) \\
&+i \cos( \Bomega t ) (\bcE' \sin( k \Delta x ) + \bcH' \cos( k \Delta x ) ) -i \sin( \Bomega t ) \cross (\bcE' \sin( k \Delta x ) + \bcH' \cos( k \Delta x ) ) \\
&-  \sin( \Bomega t ) \cdot (\bcE' \sin( k \Delta x ) +\bcH' \cos( k \Delta x ) ) \\
&+i( \sin( \Bomega t ) \cdot (\bcE' \cos( k \Delta x ) - \bcH' \sin( k \Delta x )) \\
\end{aligned}
\end{equation}

The first two lines, once integrated, produce the electric and magnetic fields, but the last two are rogue scalar and pseudoscalar terms.  These
are allowed in so far as they are still solutions to the differential equation, but do not have the desired physical meaning.

If one explicitly sums over pairs of \(\{\Bk,-\Bk\}\) of index triplets then some cancellation occurs.  The cosine cosine products and sine sine products double
and the sine cosine terms cancel.  We therefore have

\begin{equation}\label{eqn:fourierSeriesMaxwell:820}
\begin{aligned}
\inv{2} &\exp( i \Bomega t + i k \Delta x ) (\bcE' + i\bcH') \\
&= \cos( \Bomega t ) \bcE' \cos( k \Delta x ) +  \sin( \Bomega t ) \cross \bcH' \sin( k \Delta x ) \\
&+i \cos( \Bomega t ) \bcH' \cos( k \Delta x ) -i \sin( \Bomega t ) \cross \bcE' \sin( k \Delta x ) \\
&-  \sin( \Bomega t ) \cdot \bcE' \sin( k \Delta x ) \\
&-i \sin( \Bomega t ) \cdot \bcH' \sin( k \Delta x ) \\
&= (\bcE' + i\bcH') \cos( \Bomega t ) \cos( k \Delta x ) 
 -i \sin( \Bomega t ) \cross (\bcE' + i \bcH') \sin( k \Delta x ) \\
&-  \sin( \Bomega t ) \cdot (\bcE'+i\bcH) \sin( k \Delta x ) \\
\end{aligned}
\end{equation}

Here for grouping purposes \(i\) is treated as a scalar, which should be justifiable in this specific case.  A final grouping produces

\begin{equation}\label{eqn:fourierSeriesMaxwell:840}
\begin{aligned}
\inv{2} \exp( i \Bomega t + i k \Delta x ) (\bcE' + i\bcH') 
&= (\bcE' + i\bcH') \cos( \Bomega t ) \cos( k \Delta x )  \\
&-i \kcap \cross (\bcE' + i \bcH') \sin( \Abs{\Bomega} t ) \sin( k \Delta x ) \\
&-  \sin( \Bomega t ) \cdot (\bcE'+i\bcH') \sin( k \Delta x ) \\
\end{aligned}
\end{equation}

Observe that despite the grouping of the summation over the pairs of complementary sign index triplets we still have a pure scalar and pure pseudoscalar
term above.  Allowable by the math since the differential equation had no way of encoding the grade of the desired solution.  That only came from the
initial time specification of \(F(\Bx',0)\), but that is not enough.

Now, from above, we can see that one way to reconcile this grade requirement is to require both \(\kcap \cdot \bcE' = 0\), and \(\kcap \cdot \bcH' = 0\).
How can such a requirement make sense given that \(\Bk\) ranges over all directions in space, and that both \(\bcE'\) and \(\bcH'\) could conceivably 
range over many different directions in the volume of periodicity.

With no other way out, it seems that we have to impose two requirements, one on the allowable wavenumber vector directions (which in turn means we can only
pick specific orientations of the Fourier volume), and another on the field directions themselves.  The electric and magnetic fields must therefore
be directed only perpendicular to the wave number vector direction.  Wow, that is a pretty severe implication following strictly from a grade requirement!

Thinking back to \eqnref{eqn:fourier_series_maxwell:anticommutes}, it appears that an implication of this is that we have

\begin{equation}\label{eqn:fourierSeriesMaxwell:860}
\begin{aligned}
e^{i\Bomega t} F(\Bx',0) &= F(\Bx',0) e^{-i\Bomega t}
\end{aligned}
\end{equation}

Knowing this is a required condition should considerably simplify the energy and momentum questions.

%\section{FIXME}
%
%Caught myself in these notes abusing notation and probably made mistakes by combining exponentials that probably do not commute into single argument exponentials.  Go back and review all other recent previous Fourier treatments and check for and fix this if neccessary
% ... TURNS OUT THEY DID COMMUTE .... should still review other work.
