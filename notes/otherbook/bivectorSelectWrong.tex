%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

% 
% 
%\input{../peeter_prologue.tex}

\chapter{bivectorSelectWrong}
\label{chap:bivectorSelectWrong}
%\useCCL
\blogpage{http://sites.google.com/site/peeterjoot/math2009/bivectorSelectWrong.pdf}
\date{Sept 6, 2009}
\revisionInfo{\(RCSfile: bivectorSelectWrong.tex,v \) Last \(Revision: 1.2 \) \(Date: 2009/12/03 03:24:40 \)}

%\beginArtWithToc
\beginArtNoToc

As expanded so far it is

\begin{equation}\label{eqn:bivectorSelectWrong:22}
\begin{aligned}
\gpgradetwo{(x \wedge \grad)^2 } &= 
\inv{2} \left( 
 \gamma_\mu \cdot (\gamma_\nu \wedge \gamma^\alpha \wedge \gamma^\beta )
-\gamma_\nu \cdot (\gamma_\mu \wedge \gamma^\alpha \wedge \gamma^\beta ) 
\right)
x^\mu \partial^\nu x_\alpha \partial_\beta
\end{aligned}
\end{equation}

Lets expand this bivector term more completely.

\begin{equation}\label{eqn:bivectorSelectWrong:42}
\begin{aligned}
2 \gpgradetwo{(x \wedge \grad)^2 } 
%&= 
%\left( 
% \gamma_\mu \cdot (\gamma_\nu \wedge \gamma^\alpha \wedge \gamma^\beta )
%-\gamma_\nu \cdot (\gamma_\mu \wedge \gamma^\alpha \wedge \gamma^\beta ) 
%\right)
%x^\mu \partial^\nu x_\alpha \partial_\beta
&=
(\gamma_\mu \cdot \gamma_\nu (\gamma^\alpha \wedge \gamma^\beta ) %x^\mu \partial^\nu x_\alpha \partial_\beta
-\gamma_\mu \cdot \gamma^\alpha (\gamma_\nu \wedge \gamma^\beta ) %x^\mu \partial^\nu x_\alpha \partial_\beta
+\gamma_\mu \cdot \gamma^\beta (\gamma_\nu \wedge \gamma^\alpha ) ) x^\mu \partial^\nu x_\alpha \partial_\beta \\
&
- (\gamma_\nu \cdot \gamma_\mu ( \gamma^\alpha \wedge \gamma^\beta ) %x^\mu \partial^\nu x_\alpha \partial_\beta
- \gamma_\nu \cdot \gamma^\alpha ( \gamma_\mu \wedge \gamma^\beta )  %x^\mu \partial^\nu x_\alpha \partial_\beta
+ \gamma_\nu \cdot \gamma^\beta ( \gamma_\mu \wedge \gamma^\alpha ) )x^\mu \partial^\nu x_\alpha \partial_\beta \\
&=
(\gamma^\alpha \wedge \gamma^\beta ) x^\mu \partial_\mu x_\alpha \partial_\beta
-
(\gamma_\nu \wedge \gamma^\beta ) x^\mu \partial^\nu x_\mu \partial_\beta
+
(\gamma_\nu \wedge \gamma^\alpha ) x^\mu \partial^\nu x_\alpha \partial_\mu \\
&
- 
( \gamma^\alpha \wedge \gamma^\beta ) x^\mu \partial_\mu x_\alpha \partial_\beta
+ 
( \gamma_\mu \wedge \gamma^\beta ) x^\mu \partial^\nu x_\nu \partial_\beta
- 
( \gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial^\nu x_\alpha \partial_\nu \\
\end{aligned}
\end{equation}

The first and fourth terms cancel, and a change of dummy indices on the remainder, eliminating \(\beta\), gives us

\begin{equation}\label{eqn:bivectorSelectWrong:62}
\begin{aligned}
2 \gpgradetwo{(x \wedge \grad)^2 } 
&=
-
(\gamma_\nu \wedge \gamma^\alpha ) x^\mu \partial^\nu x_\mu \partial_\alpha
+
(\gamma_\nu \wedge \gamma^\alpha ) x^\mu \partial^\nu x_\alpha \partial_\mu 
+ 
( \gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial^\nu x_\nu \partial_\alpha
- 
( \gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial^\nu x_\alpha \partial_\nu \\
&=
(\gamma_\nu \wedge \gamma^\alpha ) x^\mu \partial^\nu (x_\alpha \partial_\mu - x_\mu \partial_\alpha)
+( \gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial^\nu (x_\nu \partial_\alpha - x_\alpha \partial_\nu) \\
&=
(\gamma_\nu \wedge \gamma^\alpha ) x^\mu (x_\alpha \partial^\nu \partial_\mu - x_\mu \partial^\nu \partial_\alpha)
+( \gamma_\mu \wedge \gamma^\alpha ) x^\mu (x_\nu \partial^\nu \partial_\alpha - x_\alpha \partial^\nu \partial_\nu) \\
&
+(\gamma_\nu \wedge \gamma^\nu ) x^\mu \partial_\mu 
-(\gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial_\alpha
+n ( \gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial_\alpha 
-( \gamma_\mu \wedge \gamma^\nu ) x^\mu \partial_\nu 
\\
&=
(\gamma_\nu \wedge \gamma^\alpha ) x^\mu x_\alpha \partial^\nu \partial_\mu 
+( \gamma_\mu \wedge \gamma^\alpha ) x^\mu x_\nu \partial^\nu \partial_\alpha 
-(\gamma_\mu \wedge \gamma^\alpha ) ( x^2 \partial^\mu \partial_\alpha + x^\mu x_\alpha \grad^2 ) \\
&
+(n-1)(\gamma_\mu \wedge \gamma^\alpha ) x^\mu \partial_\alpha
-( \gamma_\mu \wedge \gamma^\nu ) x^\mu \partial_\nu 
\\
&=
(\gamma_\nu \wedge \gamma^\mu ) ( x^\alpha x_\mu \partial^\nu \partial_\alpha + x^\nu x_\alpha \partial^\alpha \partial_\mu )
- ( x^2 (\grad \wedge \grad) + ( x \wedge x ) \grad^2 ) 
+(n-2) x \wedge \grad
\\
\end{aligned}
\end{equation}

The self wedges for both \(\grad\) and \(x\) are zero, and we are left with

\begin{equation}\label{eqn:bivectorSelectWrong:82}
\begin{aligned}
2 \gpgradetwo{(x \wedge \grad)^2 } 
&=
(\gamma_\nu \wedge \gamma^\mu ) ( x_\mu (x \cdot \grad) \partial^\nu + x^\nu (x \cdot \grad) \partial_\mu )
+(n-2) x \wedge \grad
\\
\end{aligned}
\end{equation}

Swapping \(\mu\) with \(\nu\) and raising and lowering we have exact cancellation of the first two terms

\begin{equation}\label{eqn:bivectorSelectWrong:102}
\begin{aligned}
2 \gpgradetwo{(x \wedge \grad)^2 } 
&=
(\gamma_\nu \wedge \gamma^\mu ) x_\mu (x \cdot \grad) \partial^\nu 
+(\gamma^\mu \wedge \gamma_\nu ) x_\mu (x \cdot \grad) \partial^\nu 
+(n-2) x \wedge \grad
\\
\end{aligned}
\end{equation}

So are left, almost mystically simplified, with just
\begin{equation}\label{eqn:qmAngularMom:onGradeTwo2}
\begin{aligned}
\gpgradetwo{(x \wedge \grad)^2 } 
&=
\frac{n-2}{2} x \wedge \grad
\end{aligned}
\end{equation}

%\EndArticle
\EndNoBibArticle
